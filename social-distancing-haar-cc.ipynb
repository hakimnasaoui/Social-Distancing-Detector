{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import combinations\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "\n",
    "INPUT_FOLDER = os.path.join(WORKING_DIR, \"input\") \n",
    "OUTPUT_FOLDER = os.path.join(WORKING_DIR, \"output\") \n",
    "\n",
    "# Video source here : https://www.youtube.com/watch?v=GJNjaRJWVP8  \n",
    "# Cutted by clideo https://clideo.com/ : cliped from 00:16.50s to 00:25.00s\n",
    "\n",
    "# There are 3 different video quality/resolutions : \n",
    "# test-video-480p / test-video-720p / test-video-1080p\n",
    "INPUT_FILENAME = os.path.join(INPUT_FOLDER, \"test-video-480p.mp4\") \n",
    "\n",
    "# File can be downloaded from here : \n",
    "# https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_fullbody.xml\n",
    "HAAR_CASCADE_FILENAME = os.path.join(INPUT_FOLDER, \"files\", \"haarcascade_fullbody.xml\")\n",
    "\n",
    "# Save processed frames into folder 'frames'\n",
    "SAVE_FRAMES = False\n",
    "FRAMES_DIR = os.path.join(OUTPUT_FOLDER, \"frames\")\n",
    "\n",
    "# Save processed frames as a new video\n",
    "SAVE_VIDEO = False\n",
    "OUT_VIDEO_FILENAME = os.path.join(OUTPUT_FOLDER, \"output-video-haar-cc.avi\")\n",
    "\n",
    "# Colors in BGR\n",
    "POSITIF_DISTANCING_DETECTION_COLOR = (0, 255, 0)\n",
    "NEGATIF_DISTANCING_DETECTION_COLOR = (0, 0, 255) \n",
    "DETECTION_LINE_WIDTH = 2\n",
    "\n",
    "# Defining unsafe distance threshold\n",
    "DISTANCE_THRESHOLD = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm /content/frames\n",
    "# !mkdir -p {FRAMES_DIR}\n",
    "if SAVE_FRAMES == True:\n",
    "    os.makedirs(FRAMES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize human body HaaR Cascade detector\n",
    "cc_fullbody = cv2.CascadeClassifier(HAAR_CASCADE_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Process completed in : 93 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cap = cv2.VideoCapture(INPUT_FILENAME)\n",
    "frames_counter=0\n",
    "\n",
    "# initalize video output func (VideoWriter object) \n",
    "if SAVE_VIDEO == True:\n",
    "    # converting video resolution from float to int.\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "\n",
    "    # Create VideoWriter for the output video\n",
    "    out = cv2.VideoWriter(OUT_VIDEO_FILENAME, \n",
    "                          cv2.VideoWriter_fourcc('M','J','P','G'), \n",
    "                          10, \n",
    "                          (frame_width,frame_height))\n",
    "\n",
    "# chech if the video exists and able to open \n",
    "if cap.isOpened() == False:\n",
    "    print('Error opening filename')\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frames_counter+=1\n",
    "        \n",
    "        # Saving frames as 1 channel in order to speed up the process\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect people in the frame\n",
    "        detected_humans = cc_fullbody.detectMultiScale(gray, 1.1, 3)\n",
    "        \n",
    "        boxes = dict()\n",
    "        i=1 # for iterating between boxes\n",
    "        \n",
    "        # Looping through all RoI of the frame\n",
    "        for (x,y,w,h) in detected_humans:\n",
    "            \n",
    "            # Saving frames boxes infos center and coordination of each RoI\n",
    "            x_center = int(x + w/2) # int((2*x+w)/2.0)\n",
    "            y_center = int(y + h/2)\n",
    "            boxes[i] = {\"center\":(x_center, y_center), \"coord\":(x, y, x+w, y+h)}\n",
    "            i+=1\n",
    "\n",
    "            people_unsafe_distance = []\n",
    "            \n",
    "            # looping though all RoIs found in this frame by taking couple of RoIs each time    \n",
    "            for (p1, box1), (p2, box2) in combinations(boxes.items(), 2):\n",
    "                \n",
    "                # Calc the distance between two persons p1 and p2 \n",
    "                (center_p1, coord_p1) = box1[\"center\"], box1[\"coord\"]\n",
    "                (center_p2, coord_p2) = box2[\"center\"], box2[\"coord\"]\n",
    "  \n",
    "                distance = math.sqrt((center_p1[0] - center_p2[0]) ** 2 \n",
    "                                     + (center_p1[1] - center_p2[1]) ** 2)\n",
    "                \n",
    "                # Check if this distance is lower than the Threshold\n",
    "                if distance < DISTANCE_THRESHOLD:\n",
    "                    if p1 not in people_unsafe_distance:\n",
    "                        people_unsafe_distance.append(p1)\n",
    "                    if p2 not in people_unsafe_distance:\n",
    "                        people_unsafe_distance.append(p2)\n",
    "            \n",
    "            # Draw the bounding box of RoI according to the threshold  \n",
    "            for id, box in boxes.items():\n",
    "                (center, coord) = box[\"center\"], box[\"coord\"]\n",
    "                if id in people_unsafe_distance:\n",
    "                    cv2.rectangle(frame, (coord[0], coord[1]), (coord[2], coord[3]), \n",
    "                                  NEGATIF_DISTANCING_DETECTION_COLOR, DETECTION_LINE_WIDTH)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (coord[0], coord[1]), (coord[2], coord[3]), \n",
    "                                  POSITIF_DISTANCING_DETECTION_COLOR, DETECTION_LINE_WIDTH)\n",
    "            \n",
    "        # Posibility to save the processed frames into a folder  \n",
    "        if SAVE_FRAMES == True:\n",
    "            cv2.imwrite(FRAMES_DIR + '/haar-cc-frame-' + str(frames_counter) + \".jpg\", frame)\n",
    "            \n",
    "        # Display the result as a video (looping frame by frame)\n",
    "        cv2.imshow(\"Detecting ... (press ENTER to stop)\", frame)\n",
    "        \n",
    "        # Posibility to write the frame into video OUT_VIDEO_FILENAME\n",
    "        if SAVE_VIDEO == True:\n",
    "            out.write(frame)\n",
    "    \n",
    "        # Posibility to stop processing the video frames using a key\n",
    "        if cv2.waitKey(1) == 13: # 13 is ENTER Key\n",
    "            break\n",
    "                \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Process completed in : %s seconds ---\" % round(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detected_humans) # detected humans (RoI) on the last processed fram\n",
    "# print(boxes) # bounding boxes of the last processed frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
